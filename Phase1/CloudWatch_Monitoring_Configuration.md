---
title: "CloudWatch Monitoring & Alerting Configuration – Phase 1"
status: "Draft"
audience: "Internal (DevOps, SRE, Engineering); External (Auditors)"
authors: "VirtualAgentics DevOps Team"
version: "0.1"
date: "2025-06-13"
gpt_model: "Generated by ChatGPT-4.1"
---

# Phase 1 CloudWatch Monitoring and Alerting Configuration

## Purpose

This document describes the monitoring and alerting setup for VirtualAgentics Phase 1, including CloudWatch Logs, Metrics, Alarms, and notifications configured to ensure the health and performance of the serverless content pipeline.  
It builds on the principles outlined in [Monitoring_and_Alerting.md](../Policies_Procedures/Monitoring_and_Alerting.md) by detailing the actual implementation for all core components in Phase 1.

---

## 1. Logging Configuration

- **Lambda Functions:**  
  Each Phase 1 Lambda (ContentGen, Review, AffLink, Publish) has an associated CloudWatch Log Group:
  - `/aws/lambda/va-contentgen`
  - `/aws/lambda/va-review`
  - `/aws/lambda/va-afflink`
  - `/aws/lambda/va-publish`
  - Log retention is set to **14 days** for all Lambda log groups.  
  - All Lambda functions use structured JSON logging for easier querying in CloudWatch Logs Insights.

- **API Gateway:**  
  The Phase 1 API Gateway (used for CMO agent triggers or content requests) has access logs and execution logs enabled:
  - Log group: `/aws/apigateway/va-phase1-cmo-api`
  - Logs include: request timestamp, request ID, HTTP method/path, caller IP, response status, and integration latency.

- **Other Services:**  
  - **S3** does not send application logs to CloudWatch, but S3 access logging is enabled to a dedicated bucket for audit if required.
  - **EventBridge:** No application logs, but all event bus activity is captured by AWS CloudTrail.
  - **DynamoDB:** If used (e.g., for metadata or agent state), DynamoDB Streams are enabled for auditing changes and can be processed by Lambda for secondary logging if needed.
  - **CloudTrail:** AWS CloudTrail is enabled at the organization level to record all API calls for compliance.

- **Centralized Logging:**  
  Currently, all logs are reviewed directly in CloudWatch. No centralized log shipping (e.g., Elasticsearch/Splunk) is in place for Phase 1, but subscription filters can be added for log forwarding if requirements change.

- **Sample Lambda Log Entry:**  
  ```json
  {
    "timestamp": "2025-06-12T19:45:23.010Z",
    "requestId": "9876-...-5432",
    "event": "AffiliateLinksInserted",
    "contentId": "abc-123",
    "linksAdded": 2,
    "function": "va-afflink"
  }
  ```

---

## 2. Metrics and Key Performance Indicators

Critical CloudWatch Metrics tracked for Phase 1:

| Component          | Metric Name                | Description / Threshold                      |
|--------------------|---------------------------|----------------------------------------------|
| ContentGen Lambda  | Invocations                | Should match # of content requests           |
| ContentGen Lambda  | Errors                     | Should be 0; non-zero triggers alert         |
| ContentGen Lambda  | Duration (p95)             | Target < 5s; alert if > 10s                  |
| AffLink Lambda     | Invocations, Errors, Duration | Errors: 0; Duration < 2s                    |
| AffLink Lambda     | LinksAdded (custom)        | # affiliate links per invocation (avg ≥ 1)   |
| Review Lambda      | Errors, Duration           | Errors: 0                                    |
| Publish Lambda     | Errors, Duration           | Errors: 0                                    |
| API Gateway (CMO)  | 5XX Error Count            | Should be 0 for successful requests          |
| API Gateway (CMO)  | Latency                    | < 1s typical                                 |
| S3 (Content Repo)  | BucketSizeBytes            | Monitor growth, alert if > expected capacity |
| DynamoDB           | ThrottledRequests          | Should remain 0                              |

- **Dashboards:**  
  A CloudWatch Dashboard named `Phase1-Pipeline-Dashboard` visualizes these metrics across all agents for quick insight: invocations, error counts, durations, and business KPIs (articles generated, links added).

---

## 3. Alerting & Notifications

### Error Alarms

- **ContentGenErrorsAlarm:**  
  - *Condition:* Lambda Errors ≥ 1 in 5 min  
  - *Action:* Sends HIGH severity alert (PagerDuty/email)

- **AffLinkErrorsAlarm:**  
  - *Condition:* Lambda Errors ≥ 1 in 5 min  
  - *Action:* Email/SNS to DevOps on-call

- **PublishErrorsAlarm:**  
  - *Condition:* Lambda Errors ≥ 1 in 5 min  
  - *Action:* Email/SNS

### Performance Alarms

- **ContentGenHighDurationAlarm:**  
  - *Condition:* p95 Duration > 10s for 15 min  
  - *Action:* Warning email to engineering team

- **AffLinkHighDurationAlarm:**  
  - *Condition:* p95 Duration > 3s for 10 min  
  - *Action:* Slack notification to #virtualagentics-alerts

- **LambdaThrottlesAlarm (All Agents):**  
  - *Condition:* Throttles > 0  
  - *Action:* Warning email

### Infrastructure Alarms

- **DynamoDBThrottlingAlarm:**  
  - *Condition:* ThrottledRequests > 0 in 5 min  
  - *Action:* PagerDuty/Slack

- **S3SizeAlert:**  
  - *Condition:* Bucket size > X GB  
  - *Action:* Email notification

### Notification and Escalation

- All CloudWatch alarms for the Phase 1 pipeline notify the `#virtualagentics-alerts` Slack channel via SNS subscription and email the on-call DevOps team.
- For critical/paging alerts (e.g., errors, throttling), PagerDuty is triggered.
- Engineers should consult the relevant agent’s [Operational Runbook](../Standards_Guidelines/Template/Agent_Runbook_Template.md) when an alarm fires for mitigation guidance.

---

## 4. Dashboard & Visualization

- The `Phase1 Content Pipeline` dashboard in CloudWatch shows:
  - Lambda error and duration graphs for all agents
  - API Gateway latency/5XX
  - S3 bucket size trends
  - Custom metrics: links added, content processed per day

- All dashboards are viewable in CloudWatch console under `/dashboards/Phase1-Pipeline-Dashboard`.
- No third-party observability tools are currently in use; AWS X-Ray is enabled on all Lambdas for tracing.

---

## 5. Log Retention & Access

- **Retention:** CloudWatch Logs for all Lambdas and API Gateway are retained for **30 days**.
- **Archiving:** No automated export to S3 at this time; can be enabled if regulatory requirements change.
- **Access Control:** Only VirtualAgentics engineering/DevOps team members have access, via group-assigned IAM permissions.
- **Auditing:** Access and changes to logs are tracked in AWS CloudTrail, reviewed quarterly per [Compliance_and_Security_Policies.md](Compliance_and_Security_Policies.md).

---

## 6. Testing & Drills

- Error simulation is performed quarterly in the dev environment to validate CloudWatch alarms and notification channels.
- Manual drill: For each alarm type, a forced error is introduced (e.g., Lambda test failure) to confirm alerts fire and are received by on-call engineers.
- All runbooks are updated with post-drill findings.

---

## 7. References

- [Monitoring_and_Alerting.md](Monitoring_and_Alerting.md) – Policy & requirements
- [Agent_Runbook_Template.md](Agent_Runbook_Template.md) – Response procedures
- AWS CloudWatch documentation: [Alarms](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/AlarmThatSendsEmail.html)
- See Terraform module `cloudwatch_alerts.tf` for configuration-as-code

---

*This document will be updated with every change in monitoring, alerting, or pipeline architecture. For questions or proposed changes, contact the VirtualAgentics DevOps Team.*
